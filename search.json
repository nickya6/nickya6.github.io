[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let‚Äôs analyze the starwars data:"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs.¬†Droid",
    "text": "Human vs.¬†Droid\n\nggplot(data = \n         starwars %>% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let‚Äôs analyze the beer_data data:\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe‚Äôll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI‚Äôll begin with these analyses and create visualizations to help us understand the data better. Let‚Äôs start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let‚Äôs calculate the average quantity purchased and average spending per purchase. For this, we‚Äôll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we‚Äôll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we‚Äôll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let‚Äôs move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI‚Äôll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let‚Äôs look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let‚Äôs proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe‚Äôll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we‚Äôll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let‚Äôs calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there‚Äôs a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let‚Äôs move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe‚Äôll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We‚Äôll do this for each brand to see which brands are most affected by promotions.\nLet‚Äôs begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn‚Äôt. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nicky Andrews",
    "section": "",
    "text": "I am a student at State University of New York at Geneseo. As an Economics major I am interested in research. My favorite research sectors are the economics of policy development and the economics of sports. Although these two sectors interest me the most, any research that may cause actual change interests me.\nOutside of economics I am a college runner at the D3 level. I have seen great success through my ability to put forth a high amount of work ethic, time management, and communication skills with teammates."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Nicky Andrews",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo, 2023 - B.A. in Economics - Minor in Data Analytics"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Nicky Andrews",
    "section": "Experience",
    "text": "Experience"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nNBA Best Lineup\n\n\n\n\n\n\n\n\n\nDec 17, 2023\n\n\nNicholas Andrews\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nNBA Best Lineup\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nNicholas Andrews\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nNBA Best Lineup\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nNicholas Andrews\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n9 min\n\n\n\n\n\n\n  \n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nNicky Andrews\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "DANL Project",
    "section": "",
    "text": "About this project üëè\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "DANL Project",
    "section": "2.1 Summary Statistics",
    "text": "2.1 Summary Statistics\n\nmpg &lt;- ggplot2::mpg\n\n\n\n\n  \n\n\n\nskim(mpg) %&gt;% \n  select(-n_missing)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n1\n4\n10\n0\n15\n0\n\n\nmodel\n1\n2\n22\n0\n38\n0\n\n\ntrans\n1\n8\n10\n0\n10\n0\n\n\ndrv\n1\n1\n1\n0\n3\n0\n\n\nfl\n1\n1\n1\n0\n5\n0\n\n\nclass\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÅ\n\n\nyear\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñá\n\n\ncyl\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n‚ñá‚ñÅ‚ñá‚ñÅ‚ñá\n\n\ncty\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ\n\n\nhwy\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÅ"
  },
  {
    "objectID": "project.html#mpg-and-a-type-of-cars",
    "href": "project.html#mpg-and-a-type-of-cars",
    "title": "DANL Project",
    "section": "2.2 MPG and a Type of Cars",
    "text": "2.2 MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) üöô üöö üöê.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\")"
  },
  {
    "objectID": "posts/nba_best_players/nba_best_players.html",
    "href": "posts/nba_best_players/nba_best_players.html",
    "title": "NBA Best Lineup",
    "section": "",
    "text": "# Load the dataset\nlibrary(readxl)\nnba_data &lt;- read_excel(\"C:/Users/nicka/OneDrive/Desktop/Fall 2023/Data 399/NBA_Goat.xlsx\")\n# View(nba_data)\n\nrmarkdown::paged_table(nba_data) \n\n\n\n  \n\n\n \n\n\n&lt;br&gt;\n\n::: {.cell}\n\n```{.r .cell-code}\n#With no weights\nlibrary(dplyr)\n\n# Assume 'nba_data' is your dataframe name\n# Standardize the columns of interest (mean=0, std=1)\nnba_data_standardized &lt;- nba_data %&gt;%\n  mutate_at(vars(Offensive_rating_playoffs, \n                 Offensive_win_shares_playoffs_per_season, \n                 VORP_playoffs_per_season, \n                 Defensive_win_shares_playoffs_per_season, \n                 Win_shares_per_48_playoffs, \n                 Box_plus_minus_playoffs, \n                 PER_playoffs, \n                 Number_of_Championships), scale)\n\n# Sum the standardized scores to get a composite score for each player\nnba_data$Composite_Score &lt;- rowSums(nba_data_standardized[,c('Offensive_rating_playoffs', \n                                                            'Offensive_win_shares_playoffs_per_season', \n                                                            'VORP_playoffs_per_season', \n                                                            'Defensive_win_shares_playoffs_per_season', \n                                                            'Win_shares_per_48_playoffs', \n                                                            'Box_plus_minus_playoffs', \n                                                            'PER_playoffs', \n                                                            'Number_of_Championships')])\n\n# Rank the players within each position based on their composite score\nposition_rankings &lt;- nba_data %&gt;%\n  arrange(Position, desc(Composite_Score)) %&gt;%\n  group_by(Position) %&gt;%\n  mutate(Rank = row_number()) %&gt;%\n  ungroup() %&gt;%\n  select(Position, Player, Composite_Score, Rank)\n\n# View the rankings for each position\nprint(position_rankings)\n\n# A tibble: 49 √ó 4\n   Position Player                Composite_Score  Rank\n   &lt;chr&gt;    &lt;chr&gt;                           &lt;dbl&gt; &lt;int&gt;\n 1 C        Nikola Jokic                    8.09      1\n 2 C        Kareem Abdul-Jabaar             4.59      2\n 3 C        Shaquelle O'Neal                3.76      3\n 4 C        Hakeem Olajuwan                 2.55      4\n 5 C        David Robinson                  0.622     5\n 6 C        Moses Malone                   -3.51      6\n 7 C        Joel Embiid                    -5.05      7\n 8 C        Patrick Ewing                  -6.42      8\n 9 PF       Tim Duncan                      5.92      1\n10 PF       Giannis Antetokounmpo           1.83      2\n# ‚Ñπ 39 more rows\n\n:::\n\n#Ranking with weighted variables\nlibrary(dplyr)\n# Define the weights for the respective metrics\nweights &lt;- c(PER_playoffs = 7, \n             Offensive_win_shares_playoffs_per_season = 8, \n             Offensive_rating_playoffs = 10, \n             VORP_playoffs_per_season = 11, \n             Box_plus_minus_playoffs = 12, \n             Number_of_Championships = 14, \n             Win_shares_per_48_playoffs = 13, \n             Defensive_win_shares_playoffs_per_season = 8)\n\n# Apply the weights to the respective columns and create new weighted columns\nnba_data_weighted &lt;- nba_data %&gt;%\n  mutate(across(all_of(names(weights)), ~ . * weights[deparse(substitute(.))], .names = \"{.col}_weighted\"))\n\n\n# Standardize the weighted columns (mean=0, std=1)\nnba_data_stand &lt;- as.data.frame(scale(nba_data_weighted[,paste0(names(weights), \"_weighted\")]))\n\n# Sum the standardized scores to get a composite score for each player\nnba_data_weighted$Composite_Score_Weighted &lt;- rowSums(nba_data_stand)\n\n\n# Rank the players within each position based on their new composite score\nposition_rankings_weighted &lt;- nba_data_weighted %&gt;%\n  arrange(Position, desc(Composite_Score_Weighted)) %&gt;%\n  group_by(Position) %&gt;%\n  mutate(Rank = row_number()) %&gt;%\n  ungroup() %&gt;%\n  select(Position, Player, Composite_Score_Weighted, Rank)\n\n# View the top-ranked players for each position\ntop_ranked_per_position &lt;- position_rankings_weighted %&gt;%\n  filter(Rank == 1) %&gt;%\n  select(Position, Player, Composite_Score_Weighted)\n\nprint(top_ranked_per_position)\n\n# A tibble: 5 √ó 3\n  Position Player         Composite_Score_Weighted\n  &lt;chr&gt;    &lt;chr&gt;                             &lt;dbl&gt;\n1 C        Nikola Jokic                       8.09\n2 PF       Tim Duncan                         5.92\n3 PG       Magic Johnson                     11.4 \n4 SF       Lebron James                      14.2 \n5 SG       Micheal Jordan                    17.2 \n\n\n\nggplot(data = nba_data_weighted,\n       aes(x = Composite_Score_Weighted,\n           y = reorder(Player, +Composite_Score_Weighted),\n           fill = Composite_Score_Weighted)) +\n  geom_point(color = \"#0072B2\", size = 1.75) +\n  geom_text(aes(label = Composite_Score_Weighted), hjust = -.25,\n            size = 2) +\n  facet_wrap(.~Position, scales = \"free_y\") +\n  scale_x_continuous(\n    name = NULL,\n    lim = c(35, 90)\n  ) +\n  scale_y_discrete(name = NULL) +\n  labs(title = 'Player Composite Score') +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = rel(.75)),\n    plot.title = element_text(size = rel(1.5),\n                              hjust = 0.5,\n                              face = 'bold'),\n    strip.text = element_text(size = rel(1.25),\n                              face = 'bold'))"
  },
  {
    "objectID": "posts/nba_best_players/nba_best_players-tmp.html",
    "href": "posts/nba_best_players/nba_best_players-tmp.html",
    "title": "NBA Best Lineup",
    "section": "",
    "text": "# Load the dataset\nnba_data &lt;- read_excel(\"C:/Users/nicka/OneDrive/Desktop/Fall 2023/Data 399/NBA_Goat.xlsx\")\n# View(nba_data)\n\n\n\n\n  \n\n\n \n\n\n\n# Define the weights for each variable\nweights &lt;- c(PER_playoffs = 7, \n             Offensive_win_shares_playoffs_per_season = 8, \n             Offensive_rating_playoffs = 10, \n             VORP_playoffs_per_season = 11, \n             Box_plus_minus_playoffs = 12, \n             Number_of_Championships = 14, \n             Win_shares_per_48_playoffs = 13, \n             Defensive_win_shares_playoffs_per_season = 8)\n\n# Standardize the relevant columns\ncolumns_to_standardize &lt;- c('PER_playoffs', 'Offensive_win_shares_playoffs_per_season', \n                            'Offensive_rating_playoffs', 'VORP_playoffs_per_season', \n                            'Box_plus_minus_playoffs', 'Number_of_Championships', \n                            'Win_shares_per_48_playoffs', 'Defensive_win_shares_playoffs_per_season')\n\nnba_data[columns_to_standardize] &lt;- scale(nba_data[columns_to_standardize])\n\n# Calculate the composite score\nnba_data$Composite_Score_Standardized &lt;- with(nba_data, \n                                              PER_playoffs * weights['PER_playoffs'] +\n                                              Offensive_win_shares_playoffs_per_season * weights['Offensive_win_shares_playoffs_per_season'] +\n                                              Offensive_rating_playoffs * weights['Offensive_rating_playoffs'] +\n                                              VORP_playoffs_per_season * weights['VORP_playoffs_per_season'] +\n                                              Box_plus_minus_playoffs * weights['Box_plus_minus_playoffs'] +\n                                              Number_of_Championships * weights['Number_of_Championships'] +\n                                              Win_shares_per_48_playoffs * weights['Win_shares_per_48_playoffs'] +\n                                              Defensive_win_shares_playoffs_per_season * weights['Defensive_win_shares_playoffs_per_season'])\n\n# Finding the player with the highest composite score in each position\nbest_composite_scores_by_position_standardized &lt;- nba_data %&gt;%\n  group_by(Position) %&gt;%\n  top_n(1, Composite_Score_Standardized) %&gt;%\n  select(Player, Position, Composite_Score_Standardized)\n\n# Print the results\nprint(best_composite_scores_by_position_standardized)\n\n# A tibble: 5 √ó 3\n# Groups:   Position [5]\n  Player         Position Composite_Score_Standardized\n  &lt;chr&gt;          &lt;chr&gt;                           &lt;dbl&gt;\n1 Micheal Jordan SG                              176. \n2 Lebron James   SF                              141. \n3 Magic Johnson  PG                              117. \n4 Tim Duncan     PF                               60.2\n5 Nikola Jokic   C                                79.1\n\nrmarkdown::paged_table(best_composite_scores_by_position_standardized)\n\n\n\n  \n\n\n \n\n\n\np &lt;- ggplot(data = nba_data,\n       aes(x = Composite_Score_Standardized,\n           y = reorder(Player, +Composite_Score_Standardized),\n           fill = Composite_Score_Standardized)) +\n  geom_point(color = \"#0072B2\", size = 1.75) +\n  geom_text(aes(label = \"\"), hjust = -.25,\n            size = 2) +\n  facet_wrap(.~Position, scales = \"free_y\") +\n  scale_x_continuous(\n    name = NULL,\n    lim = c(-100, 200)) +\n  scale_y_discrete(name = NULL) +\n  labs(title = 'Player Composite Score') +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = rel(.75)),\n    axis.text.y = element_text(size = rel(.75)),\n    plot.title = element_text(size = rel(1.5),\n                              hjust = 0.5,\n                              face = 'bold'),\n    strip.text = element_text(size = rel(1.25),\n                              face = 'bold')) + \n  theme(legend.position = \"none\")+labs(x = NULL, y = \"Player\")\nfig &lt;- ggplotly(p)\nfig\n\n\n\n\n\n##PCA\n\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(caret)\n\npredictors &lt;- scale(nba_data[, c('PER_playoffs', 'Offensive_win_shares_playoffs_per_season', \n                                 'Offensive_rating_playoffs', 'VORP_playoffs_per_season', \n                                 'Box_plus_minus_playoffs', 'Number_of_Championships', \n                                 'Win_shares_per_48_playoffs', 'Defensive_win_shares_playoffs_per_season')])\n\n# Perform PCA\npca_result &lt;- PCA(predictors, graph = FALSE)\npca_scores &lt;- data.frame(pca_result$ind$coord[, 1:5])\nresponse &lt;- nba_data$Composite_Score_Standardized\nregression_data &lt;- cbind(pca_scores, response)\n\n\nlm_model &lt;- lm(response ~ ., data = regression_data)\nsummary(lm_model)\n\n\nCall:\nlm(formula = response ~ ., data = regression_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9395 -1.8026 -0.7775  1.4320  7.0044 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.954e-15  4.188e-01   0.000   1.0000    \nDim.1        2.646e+01  2.061e-01 128.386  &lt; 2e-16 ***\nDim.2       -9.441e-01  3.620e-01  -2.608   0.0125 *  \nDim.3        1.076e+01  4.100e-01  26.250  &lt; 2e-16 ***\nDim.4        1.255e+00  4.919e-01   2.551   0.0144 *  \nDim.5        5.122e+00  6.950e-01   7.370 3.77e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.932 on 43 degrees of freedom\nMultiple R-squared:  0.9975,    Adjusted R-squared:  0.9972 \nF-statistic:  3448 on 5 and 43 DF,  p-value: &lt; 2.2e-16\n\n# Get coefficients from the regression model\nregression_coefficients &lt;- coef(lm_model)[-1]  \n\n\npca_loadings &lt;- pca_result$var$coord\n\noriginal_variable_influence &lt;- pca_loadings %*% \n  matrix(regression_coefficients, ncol = 1)\n\noriginal_variable_influence\n\n                                             [,1]\nPER_playoffs                             15.78345\nOffensive_win_shares_playoffs_per_season 25.23236\nOffensive_rating_playoffs                16.13816\nVORP_playoffs_per_season                 24.27222\nBox_plus_minus_playoffs                  19.70058\nNumber_of_Championships                  19.66313\nWin_shares_per_48_playoffs               13.73554\nDefensive_win_shares_playoffs_per_season 18.03842\n\n\n\nlibrary(gganimate)\n\ninfluence_data &lt;- as.data.frame(original_variable_influence)\ninfluence_data$Variable &lt;- rownames(original_variable_influence)\nnames(influence_data) &lt;- c(\"Influence\", \"Variable\")\n\nCoefficients &lt;- ggplot(influence_data, \n       aes(y = Variable, x = Influence,\n           fill = Variable)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  coord_flip() +\n  xlab(\"Coefficient Value\") +\n  ylab(\"Coefficients\") +\n  ggtitle(\"Coefficient Plot of Original Variables\") + \n  theme(legend.position = \"bottom\")+\n  theme(axis.text.x = element_blank()) + \n  theme(legend.text = element_text(size = 5))+ \n  theme(legend.title=element_blank()) +\n  enter_fade()+\n  exit_fade()\nCoefficients"
  },
  {
    "objectID": "ClassDANL1002.html",
    "href": "ClassDANL1002.html",
    "title": "Lecture 5",
    "section": "",
    "text": "Geomes can transform data\n\ngss_sm&lt;-gss_sm\ntable(gss_sm$bigregion)\n\n\nNortheast   Midwest     South      West \n      488       695      1052       632 \n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = bigregion))\np + geom_bar()\n\n\n\n\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = bigregion))\np + geom_bar(mapping = aes(y = ..prop.., group=1))\n\n\n\ntable(gss_sm$religion)\n\n\nProtestant   Catholic     Jewish       None      Other \n      1371        649         51        619        159 \n\nskim(gss_sm$religion)\n\n\n\n\nData summary\n\n\n\n\nName\n\n\ngss_sm$religion\n\n\n\n\nNumber of rows\n\n\n2867\n\n\n\n\nNumber of columns\n\n\n1\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nfactor\n\n\n1\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: factor\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nordered\n\n\nn_unique\n\n\ntop_counts\n\n\n\n\n\n\ndata\n\n\n18\n\n\n0.99\n\n\nFALSE\n\n\n5\n\n\nPro: 1371, Cat: 649, Non: 619, Oth: 159\n\n\n\n\n\n\n\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = religion, fill = religion))\np + geom_bar() + guides( fill = \"none\" )\n\n\n\n\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = religion, fill = religion))\np + geom_bar() + guides (fill= \"none\")\n\n\n\n\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = bigregion, fill = religion))\np + geom_bar()\n\n\n\n\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = bigregion, fill = religion))\np + geom_bar(position = \"fill\")+\n  labs(y='prop')\n\n\n\n\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = bigregion, fill = religion))\np + geom_bar(position = \"dodge\")\n\n\n\n\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = bigregion, fill = religion))\np + geom_bar(position = \"dodge\",\n             mapping = aes(y = ..prop..,group=1))\n\n\n\n\n-How can we make a side by side proportional bar chart(test)\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = bigregion, fill = religion))\np + geom_bar(position = \"dodge\",\n             mapping = aes(y = ..prop.., group = religion))\n\n\n\n\n-How can we make a side by side proportional bar chart. The sum of bar heigh =1. -Do not use facet\n\np &lt;- ggplot(data = gss_sm,\n            mapping = aes(x = religion))\np + geom_bar(position = \"dodge\",\n             mapping = aes(y = ..prop.., group = bigregion)) +\n    facet_wrap(~ bigregion, ncol = 1) \n\n\n\n\n\nmidwest&lt;-midwest\nmidwest_sum &lt;- skim(midwest)\ngss_sm_sum &lt;- skim(midwest)\ntable(gss_sm$region)\n\n\n    New England Middle Atlantic E. Nor. Central W. Nor. Central  South Atlantic \n            175             313             502             193             550 \nE. Sou. Central W. Sou. Central        Mountain         Pacific \n            205             297             235             397 \n\nunique(gss_sm$religon)\n\nNULL\n\n\n\np &lt;- ggplot(data = midwest,\n            mapping = aes(x = area))\np + geom_histogram()\n\n\n\np + geom_histogram(binwidth=.001)\n\n\n\n\n\noh_wi &lt;- c(\"OH\", \"WI\")\np &lt;- ggplot(data = filter(midwest, \n                          state %in% oh_wi),\n            mapping = aes(x = percollege, fill = state) )\np + geom_histogram(alpha = 0.4, bins = 20)\n\n\n\n\n\noh_wi &lt;- c(\"OH\", \"WI\")\np &lt;- ggplot(data = filter(midwest, \n                          state %in% oh_wi),\n            mapping = aes(x = percollege, fill = state) )\np + geom_freqpoly(bins = 20)\n\n\n\n\n\np &lt;- ggplot(data = midwest,\n            mapping = aes(x = area))\np + geom_density()\n\n\n\n\n\np &lt;- ggplot(data = midwest,\n            mapping = aes(x = area, fill = state, color = state))\np + geom_density(alpha = 0.3)\n\n\n\n\n\np &lt;- ggplot(data = filter(midwest, state %in% oh_wi),\n            mapping = aes(x = area, fill = state, color = state))\np + geom_density( alpha = 0.3, mapping =  aes(y = after_stat(scaled) )  )\n\n\n\n\n\np &lt;- ggplot(data = filter(midwest, state %in% oh_wi),\n            mapping = aes(x = area, fill = state, color = state))\np + geom_density( alpha = 0.3, )\n\n\n\n\n\ntitanic&lt;-socviz::titanic\np &lt;- ggplot(data = titanic,\n            mapping = aes(x = fate, y = percent, fill = sex))\np + geom_bar(position = \"dodge\", stat = \"identity\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\np &lt;- ggplot(data = titanic,\n            mapping = aes(x = fate, y = percent, fill = sex))\np + geom_col(position = \"dodge\") +\n  theme(legend.position = \"top\")\n\n\n\n\n\noecd_sum&lt;-oecd_sum\np&lt;-ggplot(oecd_sum,\n       aes(x = year, y = diff, fill = hi_lo))\np+geom_col(show.legend=F)+\n  labs(x=\"\",\n       y=\"Differance in years\",\n       title= \"US Life expactancy gap\",\n       subtitle= \"Diff between US and OECD\",\n       caption= \"DAta:OECD\")\n\n\n\n\n\noecd_sum&lt;-oecd_sum\np&lt;-ggplot(oecd_sum,\n       aes(x = year, y = diff))\np+geom_col(aes(fill=hi_lo),show.legend=F)+\n  geom_line()+\n  geom_point()\n\n\n\n  labs(x=\"\",\n       y=\"Differance in years\",\n       title= \"US Life expactancy gap\",\n       subtitle= \"Diff between US and OECD\",\n       caption= \"DAta:OECD\")\n\n$x\n[1] \"\"\n\n$y\n[1] \"Differance in years\"\n\n$title\n[1] \"US Life expactancy gap\"\n\n$subtitle\n[1] \"Diff between US and OECD\"\n\n$caption\n[1] \"DAta:OECD\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\n\nif (!requireNamespace(\"devtools\", quietly = TRUE))\n  install.packages(\"devtools\")\n\ndevtools::install_github(\"calligross/ggthemeassist\")\n\n#Graph tables, add labels\n\nrel_by_region &lt;- gss_sm %&gt;%\n    group_by( bigregion, religion ) %&gt;%\n    summarize( N = n() ) %&gt;%\n    mutate( freq = N / sum(N),\n            pct = round( (freq*100), 0) )\nrel_by_region\n\n# A tibble: 24 √ó 5\n# Groups:   bigregion [4]\n   bigregion religion       N    freq   pct\n   &lt;fct&gt;     &lt;fct&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Northeast Protestant   158 0.324      32\n 2 Northeast Catholic     162 0.332      33\n 3 Northeast Jewish        27 0.0553      6\n 4 Northeast None         112 0.230      23\n 5 Northeast Other         28 0.0574      6\n 6 Northeast &lt;NA&gt;           1 0.00205     0\n 7 Midwest   Protestant   325 0.468      47\n 8 Midwest   Catholic     172 0.247      25\n 9 Midwest   Jewish         3 0.00432     0\n10 Midwest   None         157 0.226      23\n# ‚Ñπ 14 more rows\n\n\n\np &lt;- ggplot( rel_by_region, \n             aes( x = bigregion, \n                  y = pct, \n                  fill = religion))\np + geom_col( position = \"dodge2\" ) +\n    labs(x = \"Region\", \n         y = \"Percent\", \n         fill = \"Religion\") +\n    theme(legend.position \n            = \"top\")\n\n\n\n\n\np &lt;- ggplot( data =rel_by_region, \n             mapping=aes(x=pct,\n                         y=religion,\n                         fill=religion))\np + geom_col()+\n  guides(fill = 'none')+\n  labs(y=\"\",\n       x=\"Percent\") +\n  facet_wrap(bigregion~ ., nrow=1)\n\n\n\n\n\norgandata &lt;- organdata\norgandata\n\n# A tibble: 238 √ó 21\n   country   year       donors   pop pop_dens   gdp gdp_lag health health_lag\n   &lt;chr&gt;     &lt;date&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n 1 Australia NA          NA    17065    0.220 16774   16591   1300       1224\n 2 Australia 1991-01-01  12.1  17284    0.223 17171   16774   1379       1300\n 3 Australia 1992-01-01  12.4  17495    0.226 17914   17171   1455       1379\n 4 Australia 1993-01-01  12.5  17667    0.228 18883   17914   1540       1455\n 5 Australia 1994-01-01  10.2  17855    0.231 19849   18883   1626       1540\n 6 Australia 1995-01-01  10.2  18072    0.233 21079   19849   1737       1626\n 7 Australia 1996-01-01  10.6  18311    0.237 21923   21079   1846       1737\n 8 Australia 1997-01-01  10.3  18518    0.239 22961   21923   1948       1846\n 9 Australia 1998-01-01  10.5  18711    0.242 24148   22961   2077       1948\n10 Australia 1999-01-01   8.67 18926    0.244 25445   24148   2231       2077\n# ‚Ñπ 228 more rows\n# ‚Ñπ 12 more variables: pubhealth &lt;dbl&gt;, roads &lt;dbl&gt;, cerebvas &lt;int&gt;,\n#   assault &lt;int&gt;, external &lt;int&gt;, txp_pop &lt;dbl&gt;, world &lt;chr&gt;, opt &lt;chr&gt;,\n#   consent_law &lt;chr&gt;, consent_practice &lt;chr&gt;, consistent &lt;chr&gt;, ccode &lt;chr&gt;\n\nskimr::skim(organdata)\n\n\n\n\nData summary\n\n\n\n\nName\n\n\norgandata\n\n\n\n\nNumber of rows\n\n\n238\n\n\n\n\nNumber of columns\n\n\n21\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\ncharacter\n\n\n7\n\n\n\n\nDate\n\n\n1\n\n\n\n\nnumeric\n\n\n13\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: character\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmin\n\n\nmax\n\n\nempty\n\n\nn_unique\n\n\nwhitespace\n\n\n\n\n\n\ncountry\n\n\n0\n\n\n1.00\n\n\n5\n\n\n14\n\n\n0\n\n\n17\n\n\n0\n\n\n\n\nworld\n\n\n14\n\n\n0.94\n\n\n6\n\n\n11\n\n\n0\n\n\n3\n\n\n0\n\n\n\n\nopt\n\n\n28\n\n\n0.88\n\n\n2\n\n\n3\n\n\n0\n\n\n2\n\n\n0\n\n\n\n\nconsent_law\n\n\n0\n\n\n1.00\n\n\n8\n\n\n8\n\n\n0\n\n\n2\n\n\n0\n\n\n\n\nconsent_practice\n\n\n0\n\n\n1.00\n\n\n8\n\n\n8\n\n\n0\n\n\n2\n\n\n0\n\n\n\n\nconsistent\n\n\n0\n\n\n1.00\n\n\n2\n\n\n3\n\n\n0\n\n\n2\n\n\n0\n\n\n\n\nccode\n\n\n0\n\n\n1.00\n\n\n2\n\n\n4\n\n\n0\n\n\n17\n\n\n0\n\n\n\n\n\nVariable type: Date\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmin\n\n\nmax\n\n\nmedian\n\n\nn_unique\n\n\n\n\n\n\nyear\n\n\n34\n\n\n0.86\n\n\n1991-01-01\n\n\n2002-01-01\n\n\n1996-07-02\n\n\n12\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nhist\n\n\n\n\n\n\ndonors\n\n\n34\n\n\n0.86\n\n\n16.48\n\n\n5.11\n\n\n5.20\n\n\n13.00\n\n\n15.10\n\n\n19.60\n\n\n33.90\n\n\n‚ñÅ‚ñá‚ñÖ‚ñÇ‚ñÅ\n\n\n\n\npop\n\n\n17\n\n\n0.93\n\n\n39921.29\n\n\n62219.22\n\n\n3514.00\n\n\n6938.00\n\n\n15531.00\n\n\n57301.00\n\n\n288369.00\n\n\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\npop_dens\n\n\n17\n\n\n0.93\n\n\n12.00\n\n\n11.09\n\n\n0.22\n\n\n1.94\n\n\n9.49\n\n\n19.11\n\n\n38.89\n\n\n‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÅ\n\n\n\n\ngdp\n\n\n17\n\n\n0.93\n\n\n22986.18\n\n\n4665.92\n\n\n12917.00\n\n\n19546.00\n\n\n22756.00\n\n\n26180.00\n\n\n36554.00\n\n\n‚ñÇ‚ñá‚ñá‚ñÉ‚ñÅ\n\n\n\n\ngdp_lag\n\n\n0\n\n\n1.00\n\n\n22574.92\n\n\n4790.71\n\n\n11434.00\n\n\n19034.25\n\n\n22158.00\n\n\n25886.50\n\n\n36554.00\n\n\n‚ñÇ‚ñá‚ñá‚ñÉ‚ñÅ\n\n\n\n\nhealth\n\n\n0\n\n\n1.00\n\n\n2073.75\n\n\n733.59\n\n\n791.00\n\n\n1581.00\n\n\n1956.00\n\n\n2407.50\n\n\n5665.00\n\n\n‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\n\n\nhealth_lag\n\n\n0\n\n\n1.00\n\n\n1972.99\n\n\n699.24\n\n\n727.00\n\n\n1542.00\n\n\n1850.50\n\n\n2290.25\n\n\n5267.00\n\n\n‚ñÜ‚ñá‚ñÇ‚ñÅ‚ñÅ\n\n\n\n\npubhealth\n\n\n21\n\n\n0.91\n\n\n6.19\n\n\n0.92\n\n\n4.30\n\n\n5.50\n\n\n6.00\n\n\n6.90\n\n\n8.80\n\n\n‚ñÇ‚ñá‚ñÖ‚ñÉ‚ñÅ\n\n\n\n\nroads\n\n\n17\n\n\n0.93\n\n\n113.04\n\n\n36.33\n\n\n58.21\n\n\n83.46\n\n\n111.22\n\n\n139.57\n\n\n232.48\n\n\n‚ñá‚ñá‚ñÜ‚ñÇ‚ñÅ\n\n\n\n\ncerebvas\n\n\n17\n\n\n0.93\n\n\n610.80\n\n\n144.45\n\n\n300.00\n\n\n500.00\n\n\n604.00\n\n\n698.00\n\n\n957.00\n\n\n‚ñÇ‚ñÖ‚ñá‚ñÉ‚ñÇ\n\n\n\n\nassault\n\n\n17\n\n\n0.93\n\n\n16.53\n\n\n17.33\n\n\n4.00\n\n\n9.00\n\n\n11.00\n\n\n16.00\n\n\n103.00\n\n\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\nexternal\n\n\n17\n\n\n0.93\n\n\n450.06\n\n\n118.19\n\n\n258.00\n\n\n367.00\n\n\n421.00\n\n\n534.00\n\n\n853.00\n\n\n‚ñÜ‚ñá‚ñÖ‚ñÅ‚ñÅ\n\n\n\n\ntxp_pop\n\n\n17\n\n\n0.93\n\n\n0.72\n\n\n0.20\n\n\n0.22\n\n\n0.63\n\n\n0.71\n\n\n0.83\n\n\n1.12\n\n\n‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñÉ\n\n\n\n\n\n\n\n\np&lt;- ggplot(data=organdata,\n           aes(x=year, y=donors))\np + geom_line() +\n  facet_wrap(.~country, nrow=4) +\n  theme(axis.text.x = element_text(angle=45))\n\n\n\n\n\np&lt;- ggplot(data= organdata,\n           aes(x=factor(year), y= donors))+\n  geom_boxplot()\np\n\n\n\n\n\nlibrary(lubridate)\np&lt;- ggplot(data= organdata,\n           aes(x=factor(year(year)), y= donors))+\n  geom_boxplot()\np\n\n\n\n\n\nlibrary(lubridate)\np&lt;- ggplot(data= organdata,\n           aes(y=country, x= donors))+\n  geom_boxplot()\np\n\n\n\n\n\nlevels(factor(organdata$country))\n\n [1] \"Australia\"      \"Austria\"        \"Belgium\"        \"Canada\"        \n [5] \"Denmark\"        \"Finland\"        \"France\"         \"Germany\"       \n [9] \"Ireland\"        \"Italy\"          \"Netherlands\"    \"Norway\"        \n[13] \"Spain\"          \"Sweden\"         \"Switzerland\"    \"United Kingdom\"\n[17] \"United States\" \n\norgandata &lt;- organdata %&gt;%\n  mutate(country = fct_reorder(country, gdp, na.rm = T) )\n\n\norgandata &lt;- organdata %&gt;%\n  mutate(country = fct_reorder(country,\n                               donors, median))\nlevels(factor(organdata$country))                 \n\n [1] \"Australia\"      \"Italy\"          \"Sweden\"         \"Denmark\"       \n [5] \"Germany\"        \"United Kingdom\" \"Netherlands\"    \"Canada\"        \n [9] \"Switzerland\"    \"Norway\"         \"France\"         \"Ireland\"       \n[13] \"Finland\"        \"United States\"  \"Belgium\"        \"Austria\"       \n[17] \"Spain\"         \n\np&lt;- ggplot(data= organdata,\n           aes(y=country, x= donors))+\n  geom_boxplot()\np          \n\n\n\n\n\nlibrary(lubridate)\np&lt;- ggplot(data= organdata,\n           aes(y=country, x= donors,\n               fill = world))+\n  geom_boxplot()\np + labs(y= NULL)+\n  theme(legend.position = \"top\")"
  },
  {
    "objectID": "ClassDANL1023.html",
    "href": "ClassDANL1023.html",
    "title": "Lecture 6",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.3     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.3     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(ggthemes)\nlibrary(ggthemr)\nlibrary(ggthemes)\nlibrary(ggrepel)\nlibrary(hrbrthemes)\n\nNOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes.\n      Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and\n      if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow\n\nlibrary(hexbin)\nlibrary(ggforce)\nlibrary(skimr)\nlibrary(socviz)\n\nknitr::opts_chunk$set(fig.width=8, fig.height=5,\n                      echo = T, eval = T, \n                      message=F, warning = F, fig.cap = \" \")  \n\ntheme_set(theme_classic() +\n          theme(strip.background =element_rect(fill=\"lightgray\"),\n                axis.title.x = element_text(size=rel(1)),\n                axis.title.y = element_text(size=rel(1)),\n                ))\n\n\nlibrary(socviz)\nrel_by_region &lt;- gss_sm %&gt;%\n    group_by( bigregion, religion ) %&gt;%\n    summarize( N = n() ) %&gt;%\n    mutate( freq = N / sum(N),\n            pct = round( (freq*100), 0) )\nrel_by_region\n\n# A tibble: 24 √ó 5\n# Groups:   bigregion [4]\n   bigregion religion       N    freq   pct\n   &lt;fct&gt;     &lt;fct&gt;      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Northeast Protestant   158 0.324      32\n 2 Northeast Catholic     162 0.332      33\n 3 Northeast Jewish        27 0.0553      6\n 4 Northeast None         112 0.230      23\n 5 Northeast Other         28 0.0574      6\n 6 Northeast &lt;NA&gt;           1 0.00205     0\n 7 Midwest   Protestant   325 0.468      47\n 8 Midwest   Catholic     172 0.247      25\n 9 Midwest   Jewish         3 0.00432     0\n10 Midwest   None         157 0.226      23\n# ‚Ñπ 14 more rows\n\n\n\np &lt;- ggplot( rel_by_region, \n             aes( x = bigregion, \n                  y = pct, \n                  fill = religion))\np + geom_col( position = \"dodge2\" ) +\n    labs(x = \"Region\", \n         y = \"Percent\", \n         fill = \"Religion\") +\n    theme(legend.position \n            = \"top\")\n\n\n\n\n\nlevels(organdata$country)\n\nNULL\n\norgandata &lt;- organdata %&gt;%\n  mutate(country = fct_reorder(country, gdp, na.rm = T) )\n\n\nby_country &lt;- organdata %&gt;% group_by(consent_law, country) %&gt;%\n    summarize(donors_mean= mean(donors, na.rm = TRUE),\n              donors_sd = sd(donors, na.rm = TRUE),\n              gdp_mean = mean(gdp, na.rm = TRUE),\n              health_mean = mean(health, na.rm = TRUE),\n              roads_mean = mean(roads, na.rm = TRUE),\n              cerebvas_mean = mean(cerebvas, na.rm = TRUE))\nby_country &lt;- organdata %&gt;% group_by(consent_law, country) %&gt;%\n  summarize_if(is.numeric, lst(mean, sd), na.rm = TRUE) %&gt;%\n  ungroup()\n\n\nlevels(organdata$country)\n\n [1] \"Spain\"          \"Ireland\"        \"Finland\"        \"United Kingdom\"\n [5] \"Italy\"          \"Australia\"      \"France\"         \"Sweden\"        \n [9] \"Belgium\"        \"Germany\"        \"Netherlands\"    \"Canada\"        \n[13] \"Denmark\"        \"Austria\"        \"Norway\"         \"Switzerland\"   \n[17] \"United States\" \n\np &lt;- ggplot(data = organdata,\n            mapping = aes(x = roads, y = donors, color = world))\np + geom_point()+\n  scale_color_viridis_d()\n\n\n\n#manual\np + geom_point()+\n  scale_color_manual(values = c('blue',\n                                'red',\n                                'green',\n                                'black'),\n                     labels = c('corporist',\n                                'liberal',\n                                'social democrat',\n                                'unclassified'),\n                    na.value = 'purple')+\n  \n  scale_y_continuous(breaks = c(10,20,30))\n\n\n\n\n\n#manual\np &lt;- ggplot(data = organdata,\n            mapping = aes(x = roads, y = donors, color = consent_law))\n\n#manual\np + geom_point()+\n  scale_color_manual(values = c('blue',\n                                'red'),\n                     labels = c('informed',\n                                'presummed'))+\n  scale_y_continuous(breaks = c(10,20,30))+\n  scale_x_continuous(breaks = seq(100,200,50))+\n  theme(legend.position = 'bottom',\n        plot.title = element_text(color = 'brown'))\n\n\n\n\n\np &lt;- ggplot(data = by_country,\n            mapping = aes(x = roads_mean, y = donors_mean))\np + geom_point() + \n  geom_text(mapping = aes(label = country),\n            hjust = -.5, vjust = 2)\n\n\n\n\n\np &lt;- ggplot(data = by_country,\n            mapping = aes(x = roads_mean, y = donors_mean))\np + geom_point() + \n  geom_text_repel(mapping = aes(label = country),\n                  family = 'serif')\n\n\n\n\n\nsocviz::elections_historic %&gt;% select(2:7)\n\n# A tibble: 49 √ó 6\n    year winner                 win_party ec_pct popular_pct popular_margin\n   &lt;int&gt; &lt;chr&gt;                  &lt;chr&gt;      &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;\n 1  1824 John Quincy Adams      D.-R.      0.322       0.309        -0.104 \n 2  1828 Andrew Jackson         Dem.       0.682       0.559         0.122 \n 3  1832 Andrew Jackson         Dem.       0.766       0.547         0.178 \n 4  1836 Martin Van Buren       Dem.       0.578       0.508         0.142 \n 5  1840 William Henry Harrison Whig       0.796       0.529         0.0605\n 6  1844 James Polk             Dem.       0.618       0.495         0.0145\n 7  1848 Zachary Taylor         Whig       0.562       0.473         0.0479\n 8  1852 Franklin Pierce        Dem.       0.858       0.508         0.0695\n 9  1856 James Buchanan         Dem.       0.588       0.453         0.122 \n10  1860 Abraham Lincoln        Rep.       0.594       0.396         0.101 \n# ‚Ñπ 39 more rows\n\np &lt;- ggplot(data = elections_historic,\n            aes(x = popular_pct, y = ec_pct))\np + geom_point()+ \n  geom_vline(xintercept = .5)+\n  geom_hline(yintercept = .5)+\n  geom_text_repel(aes(label = winner_label))+\n    scale_x_percent()+\n    scale_y_percent()"
  },
  {
    "objectID": "ClassDANL1106.html",
    "href": "ClassDANL1106.html",
    "title": "Homework 1",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.3     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.3     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(ggthemes)\nlibrary(ggthemr)\nlibrary(ggthemes)\nlibrary(ggrepel)\nlibrary(hrbrthemes)\n\nNOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes.\n      Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and\n      if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow\n\nlibrary(hexbin)\nlibrary(ggforce)\nlibrary(skimr)\nlibrary(socviz)\nlibrary(RColorBrewer)\n\nknitr::opts_chunk$set(fig.width=8, fig.height=5,\n                      echo = T, eval = T, \n                      message=F, warning = F, fig.cap = \" \")  \n\ntheme_set(theme_classic() +\n          theme(strip.background =element_rect(fill=\"lightgray\"),\n                axis.title.x = element_text(size=rel(1)),\n                axis.title.y = element_text(size=rel(1)),\n                ))\n\n\nlibrary(tidyverse); library(socviz); library(RColorBrewer)\np &lt;- ggplot(data = organdata,\n            mapping = aes(x = roads, y = donors, color = world))\np + geom_point(size = 2) + scale_color_brewer(palette = \"Set2\") +\n    theme(legend.position = \"top\")\n\n\n\np + geom_point(size = 2) + scale_color_brewer(palette = \"Pastel2\") +\n    theme(legend.position = \"top\")\n\n\n\np + geom_point(size = 2) + scale_color_brewer(palette = \"Dark2\") +\n    theme(legend.position = \"top\")\n\n\n\np + geom_point(size = 2) + \n  scale_color_manual(values = c(\"#3c6ff8\", \"#afd68d\", \"#8467ad\", \"#82857f\")) +\n  theme_ipsum() + theme(legend.position = \"top\")\n\n\n\n\n\n# color blind\nbrewer.pal.info\n\n         maxcolors category colorblind\nBrBG            11      div       TRUE\nPiYG            11      div       TRUE\nPRGn            11      div       TRUE\nPuOr            11      div       TRUE\nRdBu            11      div       TRUE\nRdGy            11      div      FALSE\nRdYlBu          11      div       TRUE\nRdYlGn          11      div      FALSE\nSpectral        11      div      FALSE\nAccent           8     qual      FALSE\nDark2            8     qual       TRUE\nPaired          12     qual       TRUE\nPastel1          9     qual      FALSE\nPastel2          8     qual      FALSE\nSet1             9     qual      FALSE\nSet2             8     qual       TRUE\nSet3            12     qual      FALSE\nBlues            9      seq       TRUE\nBuGn             9      seq       TRUE\nBuPu             9      seq       TRUE\nGnBu             9      seq       TRUE\nGreens           9      seq       TRUE\nGreys            9      seq       TRUE\nOranges          9      seq       TRUE\nOrRd             9      seq       TRUE\nPuBu             9      seq       TRUE\nPuBuGn           9      seq       TRUE\nPuRd             9      seq       TRUE\nPurples          9      seq       TRUE\nRdPu             9      seq       TRUE\nReds             9      seq       TRUE\nYlGn             9      seq       TRUE\nYlGnBu           9      seq       TRUE\nYlOrBr           9      seq       TRUE\nYlOrRd           9      seq       TRUE\n\nlibrary(dichromat)\nDefault &lt;- brewer.pal(5, \"Set2\") # RColorBrewer::brewer.pal() makes the color palettes\ntypes &lt;- c(\"deutan\", \"protan\", \"tritan\")\nnames(types) &lt;- c(\"Deuteronopia\", \"Protanopia\", \"Tritanopia\")\ncolor_table &lt;- types %&gt;%\n    purrr::map(~ dichromat(Default, .x)) %&gt;%\n    as_tibble() %&gt;%\n    add_column(Default, .before = TRUE)\ncolor_table\n\n# A tibble: 5 √ó 4\n  Default Deuteronopia Protanopia Tritanopia\n  &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;     \n1 #66C2A5 #AEAEA7      #BABAA5    #82BDBD   \n2 #FC8D62 #B6B661      #9E9E63    #F29494   \n3 #8DA0CB #9C9CCB      #9E9ECB    #92ABAB   \n4 #E78AC3 #ACACC1      #9898C3    #DA9C9C   \n5 #A6D854 #CACA5E      #D3D355    #B6C8C8   \n\n\n\n#highlight \nparty_colors &lt;- c(\"#2E74C0\", \"#CB454A\") # DEM Blue and REP Red\np0 &lt;- ggplot(data = filter(county_data, flipped == \"No\"),\n             mapping = aes(x = pop, y = black/100) )\np1 &lt;- p0 + geom_point(alpha = 0.15, color = \"gray50\") +\n  scale_x_log10(labels=scales::comma) \np1\n\n\n\n#winners for each county\np2 &lt;- p1 + geom_point(data = subset(county_data,\n                                    flipped == \"Yes\"),\n                      mapping = aes(x = pop, y = black/100,\n                                    color = partywinner16)) +\n    scale_color_manual(values = party_colors)\np2\n\n\n\n#labeling\np3 &lt;- p2 + scale_y_continuous(labels=scales::percent) +\n    labs(color = \"County flipped to ... \",\n         x = \"County Population (log scale)\",\n         y = \"Percent Black Population\",\n         title = \"Flipped counties, 2016\",\n         caption = \"Counties in gray did not flip.\")\np3\n\n\n\n#adding state label\np4 &lt;- p3 + geom_text_repel(data = filter(county_data,\n                                      flipped == \"Yes\" &\n                                      black  &gt; 25),\n                           mapping = aes(x = pop,\n                                   y = black/100,\n                                   label = state), size = 2)\np4 + theme_minimal() + theme(legend.position=\"top\")\n\n\n\n#economist theme\nlibrary(ggthemes)\np4 + theme_economist() +\n  theme(legend.position=\"top\")\n\n\n\n#Wall street journal\np4 + theme_wsj() +\n  theme(plot.title = element_text(size = rel(0.6)),\n           legend.title = element_text(size = rel(0.35)),\n           plot.caption = element_text(size = rel(0.35)),\n           legend.position = \"top\")\n\n\n\n\n\np4 + theme(legend.position = \"top\",\n           plot.title = element_text(size=rel(2),\n                                     lineheight=.5,\n                                     family=\"Times\",\n                                     face=\"bold.italic\",\n                                     colour=\"orange\"),\n           axis.text.x = element_text(size=rel(1.1),\n                                      family=\"Courier\",\n                                      face=\"bold\",\n                                      color=\"purple\"))\n\n\n\n\n\n#remove element\np4 + theme(legend.position = \"top\",\n           plot.title = element_text(size = rel(2),\n                                     lineheight = .5,\n                                     family = \"Times\",\n                                     face = \"bold.italic\",\n                                     colour = \"orange\"),\n           axis.text.x = element_blank())\n\n\n\n\n\nyrs &lt;- c(seq(1972, 1988, 4), 1993, seq(1996, 2016, 4))\nmean_age &lt;- gss_lon %&gt;%\n    filter( !is.na(age), year %in% yrs) %&gt;%\n    group_by(year) %&gt;%\n    summarize(xbar = round(mean(age, na.rm = TRUE), 0))\nmean_age$y &lt;- 0.3 \nyr_labs &lt;- data.frame(x = 85, y = 0.8, year = yrs)  # to position the age as a text label\n\np &lt;- ggplot(data = filter(gss_lon, year %in% yrs),\n            mapping = aes(x = age))\np1 &lt;- p + geom_density(fill = \"black\", color = FALSE,\n                       alpha = 0.9, mapping = aes(y = ..scaled..))\np1\n\n\n\n#add vertical line\np2 &lt;- p1 + geom_vline(data = filter(mean_age, year %in% yrs),\n               aes(xintercept = xbar), color = \"white\", size = 0.5) + \n  geom_text(data = filter(mean_age, year %in% yrs),\n              aes(x = xbar, y = y, label = xbar), nudge_x = 7.5,\n              color = \"white\", size = 3.5, hjust = 1) +\n    geom_text(data = filter(yr_labs, year %in% yrs),\n              aes(x = x, y = y, label = year))\np2\n\n\n\n#facet\np3 &lt;- p2  + facet_grid(year ~ ., switch = \"y\")\np3\n\n\n\np2a &lt;- p3 + theme(plot.title = element_text(size = 16),\n        axis.text.x= element_text(size = 12),\n        axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y = element_blank(),\n        strip.background = element_blank(),\n        strip.text.y = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(x = \"Age\", y = NULL,\n       title = \"Age Distribution of/nGSS Respondents\")\np2a\n\n\n\nggsave(plot = p2a,\n       \"agedist.png\",\n       height = 27, width = 9)\n\n\n#ridges\nlibrary(ggridges)\np &lt;- ggplot(data = gss_lon,\n            mapping = aes(x = age, \n                          y = factor(year, levels = rev(unique(year)), ordered = TRUE)))\nlibrary(ggridges)\np2b &lt;- p + geom_density_ridges(alpha = 0.6, fill = \"lightblue\", scale = 1.5) +  \n    scale_x_continuous(breaks = c(25, 50, 75)) +\n    scale_y_discrete(expand = c(0.01, 0)) + \n    labs(x = \"Age\", y = NULL, title = \"Age Distribution of\\nGSS Respondents\") +\n    theme_ridges() +  # make labels aligned properly\n    theme(title = element_text(size = 16, face = \"bold\"))\np2b\n\n\n\nggsave(plot = p2b,\n       \"ageridge.png\",\n       height = 27, width = 20)\n\n\n#combine 2 ggplots into 1\nlibrary(gridExtra)\ngrid.arrange(p2a, p2b, nrow = 1)   # sub-figures\n\n\n\n\n\nstudebt &lt;- studebt\n\np &lt;- ggplot(data = studebt,\n            aes(x = pct, y = Debt,\n                fill = type))\np + geom_col()+\n  facet_wrap(.~type)+\n  guides(fill = 'none')\n\n\n\n\n\np &lt;- ggplot(data = studebt,\n            aes(y = type, x = pct,\n                fill = Debt))\nf_labs &lt;- c(`Borrowers` = \"Percent of\\nall Borrowers\",\n            `Balances` = \"Percent of\\nall Balances\") \n\np + geom_col(position = \"fill\")+\n  # scale_x_continuous(labels = as_labeller(f_labs)) +\n  # scale_y_discrete(labels = scales::percent) +\n  scale_fill_viridis_d() +\n  guides(fill = guide_legend(reverse = TRUE,\n                             title.position = \"top\",\n                             label.position = \"bottom\",\n                             keywidth = 3, nrow = 1)) +\n  labs(x = NULL, y = NULL,\n       fill = \"Amount Owed, in thousands of dollars\",\n       caption = \"Caption\",\n       title = \"Title\",\n       subtitle = \"Subtitle\")\n\n\n\n  theme(legend.position = \"top\")\n\nList of 1\n $ legend.position: chr \"top\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE"
  },
  {
    "objectID": "ClassDANLHW2.html",
    "href": "ClassDANLHW2.html",
    "title": "Homework 1",
    "section": "",
    "text": "library(ggrepel)\nhdi_corruption &lt;- read_csv(\n  'https://bcdanl.github.io/data/hdi_corruption.csv')\n\nhdi &lt;- hdi_corruption %&gt;% \n  filter(year == 2014) %&gt;% \n  mutate(label = ifelse(country == \"Argentina\" | country == \"China\" | country == \"Egypt\" | country == \"Sengal\" | country == \"South Africa\" | country == \"Greece\", country, NA))\n\nQ2a &lt;- ggplot(data = hdi %&gt;% \n                filter(year == 2014),\n              aes(x = cpi, y = hdi))\nQ2a + geom_point(aes(color = region), alpha = .3)+\n  geom_smooth(se = F, formula = y ~ log(x), method = \"lm\")+\n   geom_text_repel(mapping = aes(label = label, color = label),\n                   box.padding = .75)+\n  guides(color = \"none\")\n\n\n\n\n\n# table(labor_supply2$NCHLT5)\n\nlibrary(readr)\nlabor_supply &lt;- read_csv(\"C:/Users/nicka/Downloads/labor_supply.csv\")\nlabor_supply2 &lt;- labor_supply %&gt;% \n  mutate(NoChild = ifelse(NCHLT5 == 0, T, F)) %&gt;% \n  filter(LABFORCE != 0) %&gt;% \n  group_by(YEAR, SEX, NoChild) %&gt;% \n  summarise(TPOP = sum(ASECWT, na.rm = T),\n            LFPOP = sum(ASECWT[LABFORCE == 2])) %&gt;% \n  mutate(LFPR = (LFPOP/TPOP)*100,\n         SEX = ifelse(SEX == 1, \"Male\", \"Female\"),\n         label = ifelse(YEAR == 2022, SEX, NA)) \n\n\nQ2b &lt;- ggplot(labor_supply2,\n              aes(x = YEAR, y = LFPR,\n                  color = SEX))\nQ2b + geom_line()+\n  facet_wrap(~NoChild, nrow = 1)+\n  geom_label_repel(aes(label = label))+\n  guides(color = 'none')\n\n\n\n\n\nlibrary(ggcorrplot) # to create correlation heatmaps using ggcorrplot()\n# install.packages(\"ggplot2\")\n# install.packages(\"corrplot\")\nlibrary(ggplot2)\n\n\nbeer_mkt &lt;- read_csv('https://bcdanl.github.io/data/beer_markets.csv')\nbeer_dummies &lt;- beer_mkt %&gt;% select(-hh, -market) \nreg &lt;- lm(data = beer_dummies,\n          beer_floz ~ .)\nbeer_dummies &lt;-  as.data.frame(model.matrix(reg))[, -1]\nbeer_dummies &lt;- cbind(beer_mkt$beer_floz ,beer_dummies)\nbeer_dummies &lt;- beer_dummies %&gt;% \n  rename(beer_floz = `beer_mkt$beer_floz`)\n\nresults &lt;- fastDummies::dummy_cols(beer_mkt %&gt;% select(-hh, -market))\ncolnames(results)\n\n  [1] \"_purchase_desc\"                              \n  [2] \"quantity\"                                    \n  [3] \"brand\"                                       \n  [4] \"dollar_spent\"                                \n  [5] \"beer_floz\"                                   \n  [6] \"price_per_floz\"                              \n  [7] \"container\"                                   \n  [8] \"promo\"                                       \n  [9] \"buyertype\"                                   \n [10] \"income\"                                      \n [11] \"childrenUnder6\"                              \n [12] \"children6to17\"                               \n [13] \"age\"                                         \n [14] \"employment\"                                  \n [15] \"degree\"                                      \n [16] \"cow\"                                         \n [17] \"race\"                                        \n [18] \"microwave\"                                   \n [19] \"dishwasher\"                                  \n [20] \"tvcable\"                                     \n [21] \"singlefamilyhome\"                            \n [22] \"npeople\"                                     \n [23] \"_purchase_desc_BUD LT BR CN\"                 \n [24] \"_purchase_desc_BUD LT BR CN 3P\"              \n [25] \"_purchase_desc_BUD LT BR CN 4P\"              \n [26] \"_purchase_desc_BUD LT BR CN 6P\"              \n [27] \"_purchase_desc_BUD LT BR CN 8P\"              \n [28] \"_purchase_desc_BUD LT BR CN 9P\"              \n [29] \"_purchase_desc_BUD LT BR CN 12P\"             \n [30] \"_purchase_desc_BUD LT BR CN 15P\"             \n [31] \"_purchase_desc_BUD LT BR CN 18P\"             \n [32] \"_purchase_desc_BUD LT BR CN 20P\"             \n [33] \"_purchase_desc_BUD LT BR CN 24P\"             \n [34] \"_purchase_desc_BUD LT BR CN 30P\"             \n [35] \"_purchase_desc_BUD LT BR CN 36P\"             \n [36] \"_purchase_desc_BUD LT BR CN F-V 18P\"         \n [37] \"_purchase_desc_BUD LT BR KG\"                 \n [38] \"_purchase_desc_BUD LT BR KG 1/2\"             \n [39] \"_purchase_desc_BUD LT BR NRB\"                \n [40] \"_purchase_desc_BUD LT BR NRB 4P\"             \n [41] \"_purchase_desc_BUD LT BR NRB 6P\"             \n [42] \"_purchase_desc_BUD LT BR NRB 8P\"             \n [43] \"_purchase_desc_BUD LT BR NRB 12P\"            \n [44] \"_purchase_desc_BUD LT BR NRB AL\"             \n [45] \"_purchase_desc_BUD LT BR NRB AL 4P\"          \n [46] \"_purchase_desc_BUD LT BR NRB AL 15P\"         \n [47] \"_purchase_desc_BUD LT BR NRB AL 24P\"         \n [48] \"_purchase_desc_BUD LT BR NRB LN\"             \n [49] \"_purchase_desc_BUD LT BR NRB LN 6P\"          \n [50] \"_purchase_desc_BUD LT BR NRB LN 12P\"         \n [51] \"_purchase_desc_BUD LT BR NRB LN 15P\"         \n [52] \"_purchase_desc_BUD LT BR NRB LN 18P\"         \n [53] \"_purchase_desc_BUD LT BR NRB LN 20P\"         \n [54] \"_purchase_desc_BUD LT BR NRB LN 24P\"         \n [55] \"_purchase_desc_BUD LT BR NRBP 6P\"            \n [56] \"_purchase_desc_BUD LT BR NRBP 24P\"           \n [57] \"_purchase_desc_BUD LT BR NRBP LN\"            \n [58] \"_purchase_desc_BUD LT BR RB LN\"              \n [59] \"_purchase_desc_BUD LT BR RB LN 12P\"          \n [60] \"_purchase_desc_BUD LT DFT BR KG BALL\"        \n [61] \"_purchase_desc_BUSCH LIGHT BR CN\"            \n [62] \"_purchase_desc_BUSCH LIGHT BR CN 4P\"         \n [63] \"_purchase_desc_BUSCH LIGHT BR CN 6P\"         \n [64] \"_purchase_desc_BUSCH LIGHT BR CN 12P\"        \n [65] \"_purchase_desc_BUSCH LIGHT BR CN 18P\"        \n [66] \"_purchase_desc_BUSCH LIGHT BR CN 24P\"        \n [67] \"_purchase_desc_BUSCH LIGHT BR CN 30P\"        \n [68] \"_purchase_desc_BUSCH LIGHT BR KG\"            \n [69] \"_purchase_desc_BUSCH LIGHT BR NRB\"           \n [70] \"_purchase_desc_BUSCH LIGHT BR NRB LN\"        \n [71] \"_purchase_desc_BUSCH LIGHT BR NRB LN 6P\"     \n [72] \"_purchase_desc_BUSCH LIGHT BR NRB LN 12P\"    \n [73] \"_purchase_desc_BUSCH LIGHT BR NRB LN 18P\"    \n [74] \"_purchase_desc_BUSCH LIGHT BR NRB LN 20P\"    \n [75] \"_purchase_desc_BUSCH LIGHT BR NRB LN 24P\"    \n [76] \"_purchase_desc_CRS LT BR CN\"                 \n [77] \"_purchase_desc_CRS LT BR CN 6P\"              \n [78] \"_purchase_desc_CRS LT BR CN 12P\"             \n [79] \"_purchase_desc_CRS LT BR CN 18P\"             \n [80] \"_purchase_desc_CRS LT BR CN 24P\"             \n [81] \"_purchase_desc_CRS LT BR CN 30P\"             \n [82] \"_purchase_desc_CRS LT BR CN 36P\"             \n [83] \"_purchase_desc_CRS LT BR CN C-B 36P\"         \n [84] \"_purchase_desc_CRS LT BR CN FBL 24P\"         \n [85] \"_purchase_desc_CRS LT BR KG\"                 \n [86] \"_purchase_desc_CRS LT BR KG 1/2\"             \n [87] \"_purchase_desc_CRS LT BR KG BALL\"            \n [88] \"_purchase_desc_CRS LT BR NRB\"                \n [89] \"_purchase_desc_CRS LT BR NRB LN\"             \n [90] \"_purchase_desc_CRS LT BR NRB LN 6P\"          \n [91] \"_purchase_desc_CRS LT BR NRB LN 12P\"         \n [92] \"_purchase_desc_CRS LT BR NRB LN 18P\"         \n [93] \"_purchase_desc_CRS LT BR NRB LN 20P\"         \n [94] \"_purchase_desc_CRS LT BR NRB LN 24P\"         \n [95] \"_purchase_desc_CRS LT BR NRBP LN\"            \n [96] \"_purchase_desc_CRS LT BR NRBP LN INSLT-B 6P\" \n [97] \"_purchase_desc_CRS LT BR NRBP LN INSLT-B 18P\"\n [98] \"_purchase_desc_CRS LT LB BR NRB\"             \n [99] \"_purchase_desc_MLR LITE BR CN\"               \n[100] \"_purchase_desc_MLR LITE BR CN 2P\"            \n[101] \"_purchase_desc_MLR LITE BR CN 4P\"            \n[102] \"_purchase_desc_MLR LITE BR CN 6P\"            \n[103] \"_purchase_desc_MLR LITE BR CN 12P\"           \n[104] \"_purchase_desc_MLR LITE BR CN 18P\"           \n[105] \"_purchase_desc_MLR LITE BR CN 24P\"           \n[106] \"_purchase_desc_MLR LITE BR CN 30P\"           \n[107] \"_purchase_desc_MLR LITE BR CN 36P\"           \n[108] \"_purchase_desc_MLR LITE BR KG 1/2\"           \n[109] \"_purchase_desc_MLR LITE BR KG 1/4\"           \n[110] \"_purchase_desc_MLR LITE BR NRB\"              \n[111] \"_purchase_desc_MLR LITE BR NRB 8P\"           \n[112] \"_purchase_desc_MLR LITE BR NRB 24P\"          \n[113] \"_purchase_desc_MLR LITE BR NRB AL 9P\"        \n[114] \"_purchase_desc_MLR LITE BR NRB LN\"           \n[115] \"_purchase_desc_MLR LITE BR NRB LN 6P\"        \n[116] \"_purchase_desc_MLR LITE BR NRB LN 18P\"       \n[117] \"_purchase_desc_MLR LITE BR NRB LN 20P\"       \n[118] \"_purchase_desc_MLR LITE BR NRB LN 24P\"       \n[119] \"_purchase_desc_MLR LITE BR NRB LN F-P 12P\"   \n[120] \"_purchase_desc_MLR LITE BR NRBP\"             \n[121] \"_purchase_desc_MLR LITE BR NRBP LN 6P\"       \n[122] \"_purchase_desc_MLR LITE BR NRBP LN 24P\"      \n[123] \"_purchase_desc_MLR LITE BR NRBP LN ES-C 24P\" \n[124] \"_purchase_desc_NATURAL LT BR CN\"             \n[125] \"_purchase_desc_NATURAL LT BR CN 3P\"          \n[126] \"_purchase_desc_NATURAL LT BR CN 4P\"          \n[127] \"_purchase_desc_NATURAL LT BR CN 6P\"          \n[128] \"_purchase_desc_NATURAL LT BR CN 12P\"         \n[129] \"_purchase_desc_NATURAL LT BR CN 18P\"         \n[130] \"_purchase_desc_NATURAL LT BR CN 24P\"         \n[131] \"_purchase_desc_NATURAL LT BR CN 30P\"         \n[132] \"_purchase_desc_NATURAL LT BR NRB\"            \n[133] \"_purchase_desc_NATURAL LT BR NRB 12P\"        \n[134] \"_purchase_desc_NATURAL LT BR NRB LN\"         \n[135] \"_purchase_desc_NATURAL LT BR NRB LN 6P\"      \n[136] \"_purchase_desc_NATURAL LT BR NRB LN 12P\"     \n[137] \"_purchase_desc_NATURAL LT BR NRB LN 20P\"     \n[138] \"brand_BUD LIGHT\"                             \n[139] \"brand_BUSCH LIGHT\"                           \n[140] \"brand_COORS LIGHT\"                           \n[141] \"brand_MILLER LITE\"                           \n[142] \"brand_NATURAL LIGHT\"                         \n[143] \"container_CAN\"                               \n[144] \"container_KEG\"                               \n[145] \"container_KEG BALL\"                          \n[146] \"container_NON REFILLABLE BOTTLE\"             \n[147] \"container_NON REFILLABLE BOTTLE ALUMINUM\"    \n[148] \"container_NON REFILLABLE BOTTLE PLASTIC\"     \n[149] \"container_REFILLABLE BOTTLE\"                 \n[150] \"buyertype_female\"                            \n[151] \"buyertype_male\"                              \n[152] \"buyertype_married\"                           \n[153] \"income_20-60k\"                               \n[154] \"income_60-100k\"                              \n[155] \"income_100-200k\"                             \n[156] \"income_200k+\"                                \n[157] \"income_under20k\"                             \n[158] \"age_&lt;30\"                                     \n[159] \"age_30-39\"                                   \n[160] \"age_40-49\"                                   \n[161] \"age_50+\"                                     \n[162] \"employment_full\"                             \n[163] \"employment_none\"                             \n[164] \"employment_part\"                             \n[165] \"degree_College\"                              \n[166] \"degree_Grad\"                                 \n[167] \"degree_HS\"                                   \n[168] \"degree_none\"                                 \n[169] \"cow_clerical/sales/service\"                  \n[170] \"cow_labor/craft/military/farm\"               \n[171] \"cow_none/retired/student\"                    \n[172] \"cow_prof\"                                    \n[173] \"race_asian\"                                  \n[174] \"race_black\"                                  \n[175] \"race_hispanic\"                               \n[176] \"race_other\"                                  \n[177] \"race_white\"                                  \n[178] \"tvcable_basic\"                               \n[179] \"tvcable_none\"                                \n[180] \"tvcable_premium\"                             \n[181] \"npeople_1\"                                   \n[182] \"npeople_2\"                                   \n[183] \"npeople_3\"                                   \n[184] \"npeople_4\"                                   \n[185] \"npeople_5plus\"                               \n\nresults &lt;- results %&gt;% \n  select(dollar_spent,\n         beer_floz,\n         price_per_floz,\n         starts_with(\"brand_\"),\n         `container_NON REFILLABLE BOTTLE`,\n         starts_with(\"promo\"),\n         buyertype_married,\n         children6to17,\n         `age_50+`,\n         employment_none) %&gt;% \n  mutate(promo = as.numeric(promo), \n         children6to17 = as.numeric(children6to17))\n\ncolnames(results) &lt;- str_replace_all(colnames(results),\n                                     \"brand_\", \"\")\ncolnames(results)\n\n [1] \"dollar_spent\"                    \"beer_floz\"                      \n [3] \"price_per_floz\"                  \"BUD LIGHT\"                      \n [5] \"BUSCH LIGHT\"                     \"COORS LIGHT\"                    \n [7] \"MILLER LITE\"                     \"NATURAL LIGHT\"                  \n [9] \"container_NON REFILLABLE BOTTLE\" \"promo\"                          \n[11] \"buyertype_married\"               \"children6to17\"                  \n[13] \"age_50+\"                         \"employment_none\"                \n\ncor_beer &lt;- cor(results)\ncor_beer &lt;- as.data.frame(cor_beer)\n\np &lt;- ggcorrplot(cor_beer, lab = T,\n                color = c(\"blue\",\"white\",\"red\")) +\n  theme(axis.text = element_text(size = rel(1.5),\n                                 face = \"bold\")) +\n  guides(fill = guide_colourbar(barheight = rel(29)))\n                                 \np                                 \n\n\n\n# Install and load reshape2 package\n# install.packages(\"reshape2\")\nlibrary(reshape2)\nlibrary(corrplot)\n\n# Assuming your data frame is named 'data'\ncorrelation_matrix &lt;- cor(beer_dummies, use = \"complete.obs\")\n\n# Customize the correlation plot using the corrplot package\ncorrplot(correlation_matrix, method = \"color\", type = \"lower\", tl.col = \"black\", tl.srt = 45)\n\n\n\n# plotting the correlation heatmap\n# library(ggplot2)\n# ggplot(data = melted_corr_beer, aes(x=Var1, y=Var2,\n                                   # fill=beer_floz)) + \n# geom_tile()"
  },
  {
    "objectID": "ClassDANLHW3.html",
    "href": "ClassDANLHW3.html",
    "title": "Homework 1",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.3     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.3     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(socviz)\nlibrary(lubridate)\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(ggthemes)\nlibrary(ggthemr)\nlibrary(ggthemes)\nlibrary(ggrepel)\nlibrary(hrbrthemes)\n\nNOTE: Either Arial Narrow or Roboto Condensed fonts are required to use these themes.\n      Please use hrbrthemes::import_roboto_condensed() to install Roboto Condensed and\n      if Arial Narrow is not on your system, please see https://bit.ly/arialnarrow\n\nlibrary(hexbin)\nlibrary(ggforce)\nlibrary(RColorBrewer)\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(fig.width=8, fig.height=5,\n                      echo = T, eval = T, \n                      message=F, warning = F, fig.cap = \" \")  \n\ntheme_set(theme_classic() +\n          theme(strip.background =element_rect(fill=\"lightgray\"),\n                axis.title.x = element_text(size=rel(1)),\n                axis.title.y = element_text(size=rel(1)),\n                ))\n\n\ndata &lt;- data_0 %&gt;% \n  group_by(survived, sex) %&gt;% \n  summarise(count = n()) %&gt;% \n  mutate(\n  survived = ifelse(survived == TRUE,1,0)\n  )\n\ndata &lt;- data(ggplot,\n             aes(x = sex,\n             color = sex))\ndata %&gt;%  \n  geom_bar()+\n  facet_grid(class ~ survived,\n              labeller = labeller(.columns = \n                                    c(0 == \"Died\",\n                                     1 == \"Survived\"))\n        ) +\n  scale_y_continuous(breaks = seq(0, 200, by = 50))+\n    labs(x = \"\")+\n    scale_fill_manual(values = c(\"orange\",\"blue\"),\n                      )\n\n\nnyc_flights &lt;- read_csv(\n  'https://bcdanl.github.io/data/nyc_flights_grouped.csv')\n\ncarrier_count &lt;- nyc_flights %&gt;%\n  group_by(carrier_full) %&gt;%\n  summarise(count = n()) %&gt;% \n  arrange(desc(count))\n\nggplot(carrier_count, aes(y = reorder(carrier_full, +count), \n                          x = count,\n                          fill = carrier_full %in% c(\"American\", \"Delta\"))) + \n  geom_bar(stat = \"identity\", alpha = .5) +  \n  geom_text(aes(label = count), hjust = -.1, vjust = -0.3, size = 3.5) +\n  scale_fill_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"grey\")) +\n  theme_wsj() +\n  theme(plot.title = element_text(size = rel(0.6)),\n           legend.title = element_text(size = rel(0.35)),\n           plot.caption = element_text(size = rel(0.1)),\n           legend.position = \"top\") + \n  theme(plot.caption = element_text(size = 10),\n    plot.title = element_text(family = \"serif\")) +labs(title = \"Number of Flights from NYC in 2013\", caption = \"Source: U.S. Department of Transportation\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\nQ3 &lt;- data %&gt;% \n  group_by(company) %&gt;% \n  mutate(NPC == \"Close\" / first(Close))\n\n\nQ3 &lt;- ggplot(data,\n             aes(x = data, y = log(NPC),\n             color = companies),\n             fct_reorder2(company, Date, NPC))\n\nQ3 + geom_line()+\n  geom_hline(yintercept = 0, linetype = 2, color = \"red\")+\n  theme(axis.text = element_text(size = 10, angle = 0.45))+\n  scale_fill_viridis_d()+\n  scale_y_continuous(breaks = seq(0, 4, by = 2))+\n  scale_x_date(breaks(as.Date(min(Q3$Date)), as.Date(max(Q3$Date)),\n                      by = \"year\"))"
  },
  {
    "objectID": "ClassDANLmidterm.html",
    "href": "ClassDANLmidterm.html",
    "title": "Midterm",
    "section": "",
    "text": "gapminder &lt;- gapminder::gapminder\ngapminder1 &lt;- gapminder %&gt;% \n  group_by(continent, country) %&gt;%\n  summarise(max = max(lifeExp)) %&gt;% \n  filter(continent != \"Oceania\")\n\n\nQ1a &lt;- ggplot(gapminder1,\n          aes(x = max, y = reorder(country, +max)))\n          \nQ1a + geom_point()+\n  facet_wrap(.~continent, scales = \"free\", nrow = 2)+\n  labs(title = \"Life Expectancy in 2007\")\n\n\n\n#Q1b: We are visializing the life expactancy for each country, seperated by continent\n\n\nn_tweets_long &lt;- read_csv(\n  'https://bcdanl.github.io/data/n_tweets_long.csv')\n\ntweets &lt;- n_tweets_long %&gt;% \n  group_by(type) %&gt;% \n  filter(type == \"n_ot_us\" | type == \"n_ot_wrld\") \n\nrt_lk &lt;-n_tweets_long %&gt;% \n  group_by(type) %&gt;% \n  filter(type == \"n_rt_lk_us\" | type == \"n_rt_lk_wrld\")\n\nQ2a &lt;- ggplot()\nQ2a + geom_bar(data = tweets, \n               aes(x = year, y = n,\n                   fill = type),\n               stat = \"identity\",position = position_dodge())+\n  geom_line(data = rt_lk, \n            aes(x = year, y = n,\n                   color = type))+\n  labs(y = \"Number of Tweets/RT/Likes\") + \n  theme(legend.position = \"top\", legend.direction = \"horizontal\")+\n  scale_fill_manual(values = c(\"maroon\", \"428bca\"))\n\n\n\n#Q2b: We are looking at a combanation of a bar graph depicting the number of tweets comparince the US to the world, and a line graph comparing the number of retweet/likes of the US and World\n\n\nelectricity &lt;- read_csv(\n  'https://bcdanl.github.io/data/electricity-usa-chn.csv')\nQ3a &lt;- ggplot(electricity,\n             aes(x = year, y = value,\n                 color = label))\nQ3a + geom_line()+\n  facet_grid(.~iso3c)+\n  scale_fill_discrete(name = \"energy\", label = c(\"coal\", \"gas\", \"hydro\", \"solar\", \"wind\")) + theme(legend.position = \"top\", legend.direction = \"horizontal\") + theme(panel.grid.major = element_line(colour = \"gray97\"))\n\n\n\nP_electricity &lt;- electricity %&gt;% \n  group_by(label, iso3c) %&gt;% \n  summarise(Percent = value/sum(value))\n\n# Q3b &lt;- ggplot(P_electricity,\n#              aes(x = year, y = Percent,\n#                  color = label))\n# \n# Q3b + geom_line()+\n#   facet_grid(.~iso3c)+\n#   scale_fill_discrete(name = \"energy\", label = c(\"coal\", \"gas\", \"hydro\", \"solar\", \"wind\")) + theme(legend.position = \"top\", legend.direction = \"horizontal\") + theme(panel.grid.major = element_line(colour = \"gray97\"))\n\n\nlibrary(ggrepel)\n\nstarbucks &lt;- read_csv(\n  'https://bcdanl.github.io/data/starbucks.csv')\n\nQ4a &lt;- starbucks %&gt;% \n  group_by(product_name) %&gt;% \n  mutate(caffeine_mgml = caffeine_mg/serv_size_m_l) %&gt;% \n  mutate(calories_kcml = calories/serv_size_m_l)\n\nQ4b &lt;- Q4a %&gt;% \n  group_by(product_name) %&gt;% \n  summarise(mean_caffeine = mean(caffeine_mgml),mean_calories = mean(calories_kcml))  \n\n\n#Q4c\n# install.packages(\"showtext\")\nlibrary(showtext)\nshowtext_auto()\nfont_add_google(\"Annie Use Your Telescope\", \"annie\")\n\nQ4c&lt;- ggplot(Q4b,\n             x = mean_calories, y = mean_caffeine,\n             color = product_name)\n\nQ4c2 &lt;- Q4c + geom_point(\n  aes(x = mean_calories, \n      y = mean_caffeine)\n  ) \n\n# Q4c2 + geom_text_repel(\n#   aes(x = mean_calories, \n#       y = mean_caffeine,\n#       label = product_name),\n#                   max.overlaps = 5,\n#                   size =  10,\n#                   min.segment.length = .5 ,\n#                   point.padding = .5,\n#                   box.padding = .25,\n#                   show.legend = NA,\n#                   family = \"annie\") +\n#   annotate(\"richtext\", \n#            x =  mean_calories, \n#            y =  mean_caffeine, \n#            label = \"&lt;img src='https://bcdanl.github.io/ex/starbucks.png' width='100'/&gt;\",\n#            fill = product_name ,\n#            size =  10, \n#            color =  product_name)"
  },
  {
    "objectID": "posts/NFL_injuries/NFL_injuries.html",
    "href": "posts/NFL_injuries/NFL_injuries.html",
    "title": "NBA Best Lineup",
    "section": "",
    "text": "library(readxl)\nNFL_injuries &lt;- read_excel(\"C:/Users/nicka/OneDrive/Desktop/Fall 2023/Data 399/nickya5.github.io/posts/NFL_injuries/NFL_injuries.xlsx\")\nView(NFL_injuries)\n\n\ncolnames(NFL_injuries)\n\n [1] \"Player\"                         \"Team\"                          \n [3] \"Place\"                          \"Date\"                          \n [5] \"Opposing_Team\"                  \"Divisional_Game\"               \n [7] \"Position\"                       \"Pre-Season_Injury?\"            \n [9] \"Week_of_Injury\"                 \"Season\"                        \n[11] \"Weeks_Injured\"                  \"Games_Missed\"                  \n[13] \"Unknown_Injury?\"                \"Reported_Injury_Type\"          \n[15] \"Total_Snaps\"                    \"Average_Playtime_Before_Injury\"\n\nNFL_injuries &lt;- na.omit(NFL_injuries)\n\nNFL_injuries$Place &lt;- as.factor(NFL_injuries$Place)\nNFL_injuries$Opposing_Team &lt;- as.factor(NFL_injuries$Opposing_Team)\nNFL_injuries$Position &lt;- as.factor(NFL_injuries$Position)\nNFL_injuries$Week_of_Injury &lt;- as.factor(NFL_injuries$Week_of_Injury) # If it's categorical\nNFL_injuries$Team &lt;- as.factor(NFL_injuries$Team)\nNFL_injuries$Divisional_Game &lt;- as.factor(NFL_injuries$Divisional_Game) # If it's categorical\n# Continue for other categorical variables\n\n# model &lt;- lm(Reported_Injury_Type ~ Place + Opposing_Team + Position + Week_of_Injury + Team + Divisional_Game + Average_Playtime_Before_Injury, data = NFL_injuries)"
  },
  {
    "objectID": "basic-example.html",
    "href": "basic-example.html",
    "title": "Habbit",
    "section": "",
    "text": "(tab content) 1\n\n\n\n(tab content) 2\n\nlibrary(tidyverse)\nggplot(mpg) +\n  geom_boxplot(aes(x = class, y = hwy))"
  },
  {
    "objectID": "basic-example.html#quarterly-results",
    "href": "basic-example.html#quarterly-results",
    "title": "Habbit",
    "section": "",
    "text": "(tab content) 1\n\n\n\n(tab content) 2\n\nlibrary(tidyverse)\nggplot(mpg) +\n  geom_boxplot(aes(x = class, y = hwy))"
  },
  {
    "objectID": "basic-example.html#section-x",
    "href": "basic-example.html#section-x",
    "title": "Habbit",
    "section": "0.2 Section X",
    "text": "0.2 Section X\nThis is my introduction.\n\nx &lt;- 1\nprint(x)\n\n[1] 1"
  },
  {
    "objectID": "basic-example.html#section-1.1",
    "href": "basic-example.html#section-1.1",
    "title": "Habbit",
    "section": "1.1 Section 1.1",
    "text": "1.1 Section 1.1\nDrink water"
  },
  {
    "objectID": "basic-example.html#section-1.2",
    "href": "basic-example.html#section-1.2",
    "title": "Habbit",
    "section": "1.2 Section 1.2",
    "text": "1.2 Section 1.2\nSleep again"
  },
  {
    "objectID": "danl-website-template/posts/beer-markets/beer-markets.html",
    "href": "danl-website-template/posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let‚Äôs analyze the beer_data data:\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")"
  },
  {
    "objectID": "danl-website-template/posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "danl-website-template/posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "danl-website-template/posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "danl-website-template/posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe‚Äôll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI‚Äôll begin with these analyses and create visualizations to help us understand the data better. Let‚Äôs start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let‚Äôs calculate the average quantity purchased and average spending per purchase. For this, we‚Äôll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we‚Äôll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we‚Äôll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let‚Äôs move on to the second analysis:"
  },
  {
    "objectID": "danl-website-template/posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "danl-website-template/posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI‚Äôll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let‚Äôs look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let‚Äôs proceed to the third analysis:"
  },
  {
    "objectID": "danl-website-template/posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "danl-website-template/posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe‚Äôll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we‚Äôll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let‚Äôs calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there‚Äôs a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let‚Äôs move to the fourth analysis:"
  },
  {
    "objectID": "danl-website-template/posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "danl-website-template/posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe‚Äôll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We‚Äôll do this for each brand to see which brands are most affected by promotions.\nLet‚Äôs begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn‚Äôt. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  }
]